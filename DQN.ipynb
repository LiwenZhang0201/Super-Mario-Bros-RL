{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nes_py.wrappers import BinarySpaceToDiscreteSpaceEnv, PenalizeDeathEnv\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT, RIGHT_ONLY\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = BinarySpaceToDiscreteSpaceEnv(env, RIGHT_ONLY)\n",
    "\n",
    "#env = PenalizeDeathEnv(env, COMPLEX_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "# env = BinarySpaceToDiscreteSpaceEnv(env, RIGHT_ONLY)\n",
    "# done = True\n",
    "# for step in range(500):\n",
    "#     if done:\n",
    "#         state = env.reset()\n",
    "#     state, reward, done, info = env.step(env.action_space.sample())\n",
    "\n",
    "#     env.render()\n",
    "\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from scipy import stats\n",
    "\n",
    "def collect_episodes(mdp, model, horizon=None, n_episodes=1):\n",
    "    paths = []\n",
    "\n",
    "    for _ in range(n_episodes):\n",
    "        observations = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        next_states = []\n",
    "\n",
    "        state = mdp.reset()\n",
    "        for _ in range(horizon):\n",
    "            \n",
    "            bern = np.random.binomial(1,0.6)\n",
    "            action = bern*np.random.randint(5) + (1-bern)*np.argmax(model.predict(state.reshape(1,240,256,3)))\n",
    "            next_state, reward, terminal, info = mdp.step(action)\n",
    "            \n",
    "            if terminal:\n",
    "                if not info['flag_get'] : \n",
    "                    reward = -3\n",
    "                else : \n",
    "                    reward = 2\n",
    "\n",
    "            observations.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            next_states.append(next_state)\n",
    "            state = copy.copy(next_state)\n",
    "            if terminal:\n",
    "                # Finish rollout if terminal state reached\n",
    "                break\n",
    "                # We need to compute the empirical return for each time step along the\n",
    "                # trajectory\n",
    "\n",
    "        paths.append(dict(\n",
    "            states=np.array(observations),\n",
    "            actions=np.array(actions),\n",
    "            rewards=np.array(rewards),\n",
    "            next_states=np.array(next_states)\n",
    "        ))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import Adam,SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 238, 254, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 119, 127, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 117, 125, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 58, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 60, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 960)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 3844      \n",
      "=================================================================\n",
      "Total params: 36,676\n",
      "Trainable params: 36,676\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Conv \n",
    "\n",
    "input_img = (240,256,3)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3),input_shape=input_img, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4,activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▉                                                                       | 10/100 [14:39<2:11:25, 87.62s/it]"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "discount = 0.9\n",
    "\n",
    "RIGHT_ONLY = RIGHT_ONLY[1:]\n",
    "\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v1')\n",
    "env = BinarySpaceToDiscreteSpaceEnv(env, RIGHT_ONLY)\n",
    "\n",
    "def create_y(states, actions, rewards, next_states, terminals):\n",
    "    Q = model.predict(states)\n",
    "    TQ = np.where(terminals, rewards, rewards + discount*np.max(model.predict(next_states).reshape(-1,4),axis=1))\n",
    "    Q[:,actions] = TQ\n",
    "    return Q\n",
    "\n",
    "capacity = 500\n",
    "horizon, num_episodes = 1000, 100\n",
    "eps = 1.0\n",
    "decay = 9/100000\n",
    "bsize = 8\n",
    "D = deque(maxlen = capacity)\n",
    "\n",
    "states_r, actions_r, rewards_r, next_states_r, terminals_r = (np.zeros((horizon, 240, 256,3)),\n",
    "                                                              np.zeros((horizon), dtype=int),\n",
    "                                                              np.zeros((horizon)),\n",
    "                                                              np.zeros((horizon, 240, 256,3)),\n",
    "                                                              np.zeros((horizon)))\n",
    "\n",
    "for episode in tqdm(range(num_episodes)):\n",
    "    state = env.reset()\n",
    "    for t in range(horizon):\n",
    "        bern = np.random.binomial(1, eps)\n",
    "        action = bern*np.random.randint(4) + (1-bern)*np.argmax(model.predict(state.reshape(1,240,256,3)))\n",
    "        next_state, reward, terminal, info = env.step(action)\n",
    "        env.render()\n",
    "        states_r[t], actions_r[t], rewards_r[t], next_states_r[t], terminals_r[t] = [state, action,\n",
    "                                                                                     reward, next_state, terminal]\n",
    "        #D.append([state, action, reward, next_state, terminal])\n",
    "        state = copy.copy(next_state)\n",
    "        if terminal : state = env.reset()\n",
    "            \n",
    "        if episode != 0 : minibatch = np.random.choice(np.arange(horizon), bsize)\n",
    "        else : minibatch = np.random.choice(np.arange(t+1), min(bsize, t+1))\n",
    "        \n",
    "        data, y = states_r[minibatch], create_y(states_r[minibatch], actions_r[minibatch], rewards_r[minibatch],\n",
    "                                              next_states_r[minibatch], terminals_r[minibatch])\n",
    "        model.train_on_batch(data, y)\n",
    "        eps = max(0.1, eps - decay)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v1')\n",
    "env = BinarySpaceToDiscreteSpaceEnv(env, RIGHT_ONLY)\n",
    "done = True\n",
    "for step in range(500):\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    action = np.argmax(model.predict(state.reshape(1,240,256,3)))\n",
    "    state, reward, done, info = env.step(action)\n",
    "#     if done : \n",
    "#         h = state\n",
    "#         print(reward)\n",
    "#         print(done)\n",
    "    env.render()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 49\n"
     ]
    }
   ],
   "source": [
    "discount = 0.9\n",
    "for t in range(50): \n",
    "    path = collect_episodes(env, model, horizon=200)[0]\n",
    "    Q = model.predict(path['states'])\n",
    "    TQ = path['rewards'] + discount*np.max(model.predict(path['next_states']),axis=1)\n",
    "    Q[:,path['actions']] = TQ\n",
    "    model.fit(path['states'], Q, verbose=0)\n",
    "    if (t+1)%50 == 0 : \n",
    "        print('iteration {}'.format(t))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBrosNoFrameskip-v0')\n",
    "env = BinarySpaceToDiscreteSpaceEnv(env, RIGHT_ONLY)\n",
    "done = True\n",
    "for step in range(500):\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "    action = np.argmax(model.predict(state.reshape(1,240,256,3)))\n",
    "    state, reward, done, info = env.step(action)\n",
    "#     if done : \n",
    "#         h = state\n",
    "#         print(reward)\n",
    "#         print(done)\n",
    "    env.render()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(h)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.4987988e-05, 7.7925561e-06, 7.5290119e-03, 9.5475543e-01,\n",
       "        1.6911041e-06, 6.2990716e-06, 1.7567293e-09, 8.4045865e-07,\n",
       "        1.3829242e-08, 3.6480512e-02, 8.9927134e-06, 1.1744222e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "a,b,c,d = env.step(env.action_space.sample())\n",
    "model.predict(a.reshape(1,240,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
